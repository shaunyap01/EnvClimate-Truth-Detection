import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from scipy.sparse import hstack

# Define the label mapping for binary classification
label_mapping = {
    'pants-fire': 0,
    'false': 0,
    'barely-true': 0,
    'half-true': 1,
    'mostly-true': 1,
    'true': 1
}

# Apply label mapping to convert target labels into binary labels
train_data['binary_label'] = train_data['target'].map(label_mapping)
val_data['binary_label'] = val_data['target'].map(label_mapping)
test_data['binary_label'] = test_data['target'].map(label_mapping)

# Initialize and fit TF-IDF vectorizer on training data
tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)
X_train_tfidf = tfidf_vectorizer.fit_transform(train_data['statement_clean'])
X_val_tfidf = tfidf_vectorizer.transform(val_data['statement_clean'])
X_test_tfidf = tfidf_vectorizer.transform(test_data['statement_clean'])

# Standardize additional numerical features
scaler = StandardScaler(with_mean=False)
X_train_num = scaler.fit_transform(train_data[['flesch_kincaid_ease', 'polarity', 'subjectivity']].values)
X_val_num = scaler.transform(val_data[['flesch_kincaid_ease', 'polarity', 'subjectivity']].values)
X_test_num = scaler.transform(test_data[['flesch_kincaid_ease', 'polarity', 'subjectivity']].values)

# Combine TF-IDF features with standardized numerical features
X_train = hstack([X_train_tfidf, X_train_num])
X_val = hstack([X_val_tfidf, X_val_num])
X_test = hstack([X_test_tfidf, X_test_num])

# Apply SMOTE to balance the training data
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, train_data['binary_label'])

# Initialize the Gradient Boosting Classifier
gb_classifier = GradientBoostingClassifier(random_state=42)

# Define the hyperparameter grid for GridSearchCV
param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'subsample': [0.8, 1.0]
}

# Set up GridSearchCV for hyperparameter tuning
grid_search = GridSearchCV(estimator=gb_classifier, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)

# Fit the model on the balanced training data
grid_search.fit(X_train_balanced, y_train_balanced)

# Print the best combination of hyperparameters
print(f"Best Hyperparameters: {grid_search.best_params_}")

# Use the best model for final predictions
best_gb_classifier = grid_search.best_estimator_
test_predictions = best_gb_classifier.predict(X_test)

# Calculate accuracy, precision, recall, and confusion matrix
accuracy = accuracy_score(test_data['binary_label'], test_predictions)
precision = precision_score(test_data['binary_label'], test_predictions, average='binary')
recall = recall_score(test_data['binary_label'], test_predictions, average='binary')
conf_matrix = confusion_matrix(test_data['binary_label'], test_predictions, labels=[0, 1])

# Display the results
print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print('Confusion Matrix:')
print(conf_matrix)
